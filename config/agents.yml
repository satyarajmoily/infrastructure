# AI Agent Team Configuration
# This file persists across restarts and defines agent capabilities

platform_agents:
  coding-ai-agent:
    enabled: true
    port: 8002
    image: "coding-ai-agent:latest"
    capabilities:
      - "code_generation"
      - "pr_creation" 
      - "testing"
      - "requirement_analysis"
      - "local_environment_setup"
    target_repositories: "all"  # Can work on any configured repository
    environment:
      # LLM Configuration - Coding Agent uses GPT-4o for code generation
      - "LLM_PROVIDER=openai"
      - "LLM_MODEL=gpt-4.1-nano-2025-04-14"
      - "LLM_TEMPERATURE=0.1"
      - "LLM_MAX_TOKENS=4000"
      - "LLM_TIMEOUT=60"
      - "WORKSPACE_BASE_PATH=/tmp/coding-agent-workspaces"
    volumes:
      - "coding-agent-workspaces:/tmp/coding-agent-workspaces"
      - "/var/run/docker.sock:/var/run/docker.sock"
    resources:
      memory: "2Gi"
      cpu: "1"
    auto_restart: true
    health_check:
      endpoint: "/health"
      interval: "30s"
      
  devops-ai-agent:
    enabled: true
    port: 8001
    image: "devops-ai-agent:latest"
    capabilities:
      - "monitoring"
      - "alerting"
      - "auto_recovery"
      - "performance_analysis"
      - "infrastructure_management"
    target_repositories: "all"  # Can monitor any configured repository
    environment:
      # LLM Configuration - DevOps Agent uses GPT-4 for infrastructure reasoning
      - "LLM_PROVIDER=openai"
      - "LLM_MODEL=gpt-4.1-nano-2025-04-14"
      - "LLM_TEMPERATURE=0.1"
      - "LLM_MAX_TOKENS=4000"
      - "LLM_TIMEOUT=60"
      - "SAFETY_MODE=true"
      - "MONITORING_INTERVAL=30"
      - "PROMETHEUS_URL=http://prometheus:9090"
      - "ALERTMANAGER_URL=http://alertmanager:9093"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    resources:
      memory: "1Gi"
      cpu: "0.5"
    auto_restart: true
    health_check:
      endpoint: "/health"
      interval: "30s"

# Future agent configurations (disabled by default)
future_agents:
  security-ai-agent:
    enabled: false
    port: 8003
    capabilities:
      - "vulnerability_scanning"
      - "security_fixes"
      - "compliance_checking"
    target_repositories: "all"
    environment:
      # LLM Configuration - Security Agent could use Claude for security analysis
      - "LLM_PROVIDER=anthropic"
      - "LLM_MODEL=claude-3-sonnet-20240229"
      - "LLM_TEMPERATURE=0.0"
      - "LLM_MAX_TOKENS=3000"
    
  testing-ai-agent:
    enabled: false
    port: 8004
    capabilities:
      - "test_generation"
      - "test_automation"
      - "performance_testing"
    target_repositories: "all"
    environment:
      # LLM Configuration - Testing Agent uses GPT-4o-mini for cost efficiency
      - "LLM_PROVIDER=openai"
      - "LLM_MODEL=gpt-4o-mini"
      - "LLM_TEMPERATURE=0.2"
      - "LLM_MAX_TOKENS=2000"

# Agent startup behavior
startup:
  load_repositories_on_start: true
  auto_configure_monitoring: true
  validate_repository_access: true
  setup_workspaces: true 